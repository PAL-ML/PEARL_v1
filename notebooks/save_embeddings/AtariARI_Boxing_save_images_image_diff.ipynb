{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AtariARI_Boxing_save_images_image_diff",
      "provenance": [],
      "collapsed_sections": [
        "yq8xAJ8Yh2r0",
        "hGEGKk7Gisky",
        "cJsMc0t13zlV",
        "7RhJsO6aRO8M"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4IkUHvT0BCx"
      },
      "source": [
        "# Mount Drive & Login to Wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to-vnzjGn3-4",
        "outputId": "b0ab65b8-0456-4fcb-c23f-dc591662ee42"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "if 'PAL_2021' not in os.listdir():\n",
        "    user = input('Github User name: ')\n",
        "    password = getpass('Password: ')\n",
        "    password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "    cmd_string = 'git clone https://{0}:{1}@github.com/minakhan01/PAL_2021.git'.format(user, password)\n",
        "\n",
        "    os.system(cmd_string)\n",
        "    cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 5.3MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n",
            "Github User name: crimsontrigger\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq8xAJ8Yh2r0"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Gsu6oxdIQm",
        "outputId": "35627760-a848-4a45-acc6-796e7ddcc404"
      },
      "source": [
        "!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1{torch_version_suffix} (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 0.4.1, 0.4.1.post2, 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.2.0+cpu, 1.2.0+cu92, 1.3.0, 1.3.0+cpu, 1.3.0+cu100, 1.3.0+cu92, 1.3.1, 1.3.1+cpu, 1.3.1+cu100, 1.3.1+cu92, 1.4.0, 1.4.0+cpu, 1.4.0+cu100, 1.4.0+cu92, 1.5.0, 1.5.0+cpu, 1.5.0+cu101, 1.5.0+cu92, 1.5.1, 1.5.1+cpu, 1.5.1+cu101, 1.5.1+cu92, 1.6.0, 1.6.0+cpu, 1.6.0+cu101, 1.6.0+cu92, 1.7.0, 1.7.0+cpu, 1.7.0+cu101, 1.7.0+cu110, 1.7.0+cu92, 1.7.1, 1.7.1+cpu, 1.7.1+cu101, 1.7.1+cu110, 1.7.1+cu92, 1.7.1+rocm3.7, 1.7.1+rocm3.8, 1.8.0, 1.8.0+cpu, 1.8.0+cu101, 1.8.0+cu111, 1.8.0+rocm3.10, 1.8.0+rocm4.0.1, 1.8.1, 1.8.1+cpu, 1.8.1+cu101, 1.8.1+cu102, 1.8.1+cu111, 1.8.1+rocm3.10, 1.8.1+rocm4.0.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch==1.7.1{torch_version_suffix}\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNrCTmycdfNG",
        "outputId": "6901f4c2-2e40-4f41-c3cf-da87393bd9b7"
      },
      "source": [
        "!pip install ftfy regex tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41935 sha256=96fc647d7ced61bf8da58ced8a85a252555373ba4c43c0346f690be378ff291a\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGEGKk7Gisky"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZTQ396QdqKC"
      },
      "source": [
        "# ML libraries\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "# Data processing\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, Normalize\n",
        "\n",
        "# Misc\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PAL_2021.PAL_HILL.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJsMc0t13zlV"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOu1M-G53yWt"
      },
      "source": [
        "class ClipEncoder(nn.Module):\n",
        "  def __init__(self, input_channels, feature_size):\n",
        "    super().__init__()\n",
        "    self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    self.clip_model, _ = clip.load(\"ViT-B/32\", device=self.device, jit=False)\n",
        "    self.preprocess = Compose([\n",
        "        Resize((224, 224), interpolation=Image.BICUBIC),\n",
        "        Normalize(\n",
        "          (0.48145466, 0.4578275, 0.40821073),\n",
        "          (0.26862954, 0.26130258, 0.27577711)\n",
        "        )\n",
        "    ])\n",
        "    self.feature_size = feature_size\n",
        "    self.input_channels = input_channels\n",
        "\n",
        "  def forward(self, inputs):\n",
        "      x = self.get_clip_features(inputs)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      return x\n",
        "  \n",
        "  def get_clip_features(self, image):\n",
        "    with torch.no_grad():\n",
        "      image_features = self.clip_model.encode_image(self.preprocess(image)).float()\n",
        "    return image_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RhJsO6aRO8M"
      },
      "source": [
        "# Get episode data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hba4-17CnznI",
        "outputId": "5ac9fa94-e127-4a04-dee4-ed479b279a5e"
      },
      "source": [
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "# encoder_model_name = \"ViT-B/32\"\n",
        "experiment_id = \"BoxingNoFrameskip-v4-latest-04-05-2021\"\n",
        "\n",
        "folder_name = experiment_id\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1WBE9nsfDURndHh73WfaPC9rwrAqfe_GT'\n",
        "\n",
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = get_folder_id(drive, parentid, folder_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: BoxingNoFrameskip-v4-latest-04-05-2021, id: 1Afg-cErevibvouAiNkqz7l4ZTArSUq4z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3EVGErgRO8N",
        "outputId": "61b230df-a2da-497e-867c-9421aacc222c"
      },
      "source": [
        "download_file_by_name(drive, folderid[0], 'train_eps.npz')\n",
        "download_file_by_name(drive, folderid[0], \"test_eps.npz\")\n",
        "download_file_by_name(drive, folderid[0], \"val_eps.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_eps.npz from GDrive\n",
            "Downloading test_eps.npz from GDrive\n",
            "Downloading val_eps.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX9XTD3FnAHG"
      },
      "source": [
        "tr_episodes = np.load('train_eps.npz', allow_pickle=True)\n",
        "test_episodes = np.load('test_eps.npz', allow_pickle=True)\n",
        "val_episodes = np.load('val_eps.npz', allow_pickle=True)\n",
        "\n",
        "tr_episodes = tr_episodes[\"arr_0\"]\n",
        "test_episodes = test_episodes[\"arr_0\"]\n",
        "val_episodes = val_episodes[\"arr_0\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqbNrfT33lCD"
      },
      "source": [
        "# Run probe training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geaRUQCAviUA",
        "outputId": "0dcae1f9-5219-498e-d2f1-a2f385cb95a7"
      },
      "source": [
        "!pip install --upgrade scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/01/3a830f3df578ea3ed94ee7fd9f91e85c3dec2431d8548ab1c91869e51450/scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2MB 103kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.4.8)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-image\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "Successfully installed scikit-image-0.18.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5XM67amgare",
        "outputId": "68fd42c1-d8c5-472b-b992-2c0782e02741"
      },
      "source": [
        "!pip install --upgrade imutils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esR0Q0WCI3Rq"
      },
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMC2LwfFgiVx"
      },
      "source": [
        "def image_diff(img1,img2, img1_nop):\n",
        "  # load the two input images\n",
        "  imageA = img1\n",
        "  imageB = img2\n",
        "  # convert the images to grayscale\n",
        "  grayA = cv2.cvtColor(imageA, cv2.COLOR_RGB2GRAY)\n",
        "  grayB = cv2.cvtColor(imageB, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  # compute the Structural Similarity Index (SSIM) between the two\n",
        "  # images, ensuring that the difference image is returned\n",
        "  (score, diff) = ssim(grayA, grayB, full=True)\n",
        "  diff = (diff*255).astype(\"uint8\")\n",
        "\n",
        "  # threshold the difference image, followed by finding contours to\n",
        "  # obtain the regions of the two input images that differ\n",
        "  thresh = cv2.threshold(diff, 0, 1,\n",
        "    cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "  cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
        "    cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "\n",
        "  maskkkkk = np.zeros((210,160), dtype=\"uint8\")\n",
        "\n",
        "  # loop over the contours\n",
        "  for c in cnts:\n",
        "    (x, y, w, h) = cv2.boundingRect(c)\n",
        "    cv2.rectangle(maskkkkk, (x, y), (x + w, y + h), 1, -1)\n",
        "\n",
        "  new_list = [maskkkkk,maskkkkk,maskkkkk]\n",
        "  stacked_thresh = np.stack(new_list)\n",
        "  final_masked = torch.from_numpy(stacked_thresh * img1_nop)\n",
        "\n",
        "  if score == 1:\n",
        "    final_masked = torch.from_numpy(img1_nop)\n",
        "\n",
        "  return final_masked,diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9RLS4e-FN3X"
      },
      "source": [
        "length_tr = len(tr_episodes)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYYNNc5zT1Hk",
        "outputId": "e8244a4c-f440-4cfc-e7e6-39266e65522b"
      },
      "source": [
        "all_masked_images_half1 = []\n",
        "all_masks_half1 = []\n",
        "j = 0\n",
        "for ep in tqdm(tr_episodes):\n",
        "  if j<length_tr:\n",
        "    ep_images = []\n",
        "    ep_mask = []\n",
        "    for i in range(len(ep)):\n",
        "      if i + 4 < len(ep):\n",
        "        np_img = ep[i].permute(1, 2, 0).numpy()\n",
        "        np_img2 = ep[i+4].permute(1, 2, 0).numpy()\n",
        "        np_img_no = ep[i].numpy()\n",
        "        masked_image, mask = image_diff(np_img,np_img2,np_img_no)\n",
        "        ep_images.append(masked_image)\n",
        "        ep_mask.append(mask)\n",
        "      else:\n",
        "        mask = np.full((210,160), 255)\n",
        "        ep_images.append(ep[i])\n",
        "        ep_mask.append(mask)\n",
        "    all_masked_images_half1.append(ep_images)\n",
        "    all_masks_half1.append(ep_mask)\n",
        "  j = j + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [01:01<00:00,  3.05s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEqGrSWMTtLC",
        "outputId": "6cf67716-d6ca-4576-cf7f-c7d608c134bb"
      },
      "source": [
        "all_masked_images_half2 = []\n",
        "all_masks_half2 = []\n",
        "j = 0\n",
        "for ep in tqdm(tr_episodes):\n",
        "  if j>=length_tr:\n",
        "    ep_images = []\n",
        "    ep_mask = []\n",
        "    for i in range(len(ep)):\n",
        "      if i + 4 < len(ep):\n",
        "        np_img = ep[i].permute(1, 2, 0).numpy()\n",
        "        np_img2 = ep[i+4].permute(1, 2, 0).numpy()\n",
        "        np_img_no = ep[i].numpy()\n",
        "        masked_image, mask = image_diff(np_img,np_img2,np_img_no)\n",
        "        ep_images.append(masked_image)\n",
        "        ep_mask.append(mask)\n",
        "      else:\n",
        "        mask = np.full((210,160), 255)\n",
        "        ep_images.append(ep[i])\n",
        "        ep_mask.append(mask)\n",
        "    all_masked_images_half2.append(ep_images)\n",
        "    all_masks_half2.append(ep_mask)\n",
        "  j = j + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [01:01<00:00,  3.09s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arQX3e_ZI6rL",
        "outputId": "c37d9b47-6d9f-4317-f970-b379964205b4"
      },
      "source": [
        "all_masked_images_test = []\n",
        "all_masks_test = []\n",
        "for ep in tqdm(test_episodes):\n",
        "  ep_images = []\n",
        "  ep_mask = []\n",
        "  for i in range(len(ep)):\n",
        "    if i + 4 < len(ep):\n",
        "      np_img = ep[i].permute(1, 2, 0).numpy()\n",
        "      np_img2 = ep[i+4].permute(1, 2, 0).numpy()\n",
        "      np_img_no = ep[i].numpy()\n",
        "      masked_image, mask = image_diff(np_img,np_img2,np_img_no)\n",
        "      ep_images.append(masked_image)\n",
        "      ep_mask.append(mask)\n",
        "    else:\n",
        "      mask = np.full((210,160), 255)\n",
        "      ep_images.append(ep[i])\n",
        "      ep_mask.append(mask)\n",
        "  all_masked_images_test.append(ep_images)\n",
        "  all_masks_test.append(ep_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:31<00:00,  5.18s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGxVOwAJI_8o",
        "outputId": "465fafd3-1d0d-46f6-88e4-f7c6b4721173"
      },
      "source": [
        "all_masked_images_val = []\n",
        "all_masks_val = []\n",
        "for ep in tqdm(val_episodes):\n",
        "  ep_images = []\n",
        "  ep_mask = []\n",
        "  for i in range(len(ep)):\n",
        "    if i + 4 < len(ep):\n",
        "      np_img = ep[i].permute(1, 2, 0).numpy()\n",
        "      np_img2 = ep[i+4].permute(1, 2, 0).numpy()\n",
        "      np_img_no = ep[i].numpy()\n",
        "      masked_image, mask = image_diff(np_img,np_img2,np_img_no)\n",
        "      ep_images.append(masked_image)\n",
        "      ep_mask.append(mask)\n",
        "    else:\n",
        "      mask = np.full((210,160), 255)\n",
        "      ep_images.append(ep[i])\n",
        "      ep_mask.append(mask)\n",
        "  all_masked_images_val.append(ep_images)\n",
        "  all_masks_val.append(ep_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:18<00:00,  6.14s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CLBWgp0JnO1",
        "outputId": "b9f5f706-827f-4919-e9c8-3ba18224d969"
      },
      "source": [
        "np.savez(\"image_diff_masked_train_half_new\",all_masked_images_half1)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masked_train_half_new.npz\")\n",
        "np.savez(\"image_diff_masked_train_half2_new\",all_masked_images_half2)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masked_train_half2_new.npz\")\n",
        "np.savez(\"image_diff_masked_test_new\",all_masked_images_test)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masked_test_new.npz\")\n",
        "np.savez(\"image_diff_masked_val_new\",all_masked_images_val)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masked_val_new.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded image_diff_masked_train_half2_new.npz to https://drive.google.com/drive/u/1/folders/1Afg-cErevibvouAiNkqz7l4ZTArSUq4z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shZQ0cooq_tk",
        "outputId": "6f65ca77-6b59-4b03-f6dc-9fb6f632312b"
      },
      "source": [
        "np.savez(\"image_diff_masks_train_half_new\",all_masks_half1)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masks_train_half_new.npz\")\n",
        "np.savez(\"image_diff_masks_train_half2_new\",all_masks_half2)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masks_train_half2_new.npz\")\n",
        "np.savez(\"image_diff_masks_test_new\",all_masks_test)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masks_test_new.npz\")\n",
        "np.savez(\"image_diff_masks_val_new\",all_masks_val)\n",
        "save_to_drive(drive, folderid[0], \"image_diff_masks_val_new.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded image_diff_masks_train_half2_new.npz to https://drive.google.com/drive/u/1/folders/1Afg-cErevibvouAiNkqz7l4ZTArSUq4z\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}